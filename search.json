[
  {
    "objectID": "standalone-projects/swiss_electricity_transition_R/Swiss_Electricity_Transition_Project.html",
    "href": "standalone-projects/swiss_electricity_transition_R/Swiss_Electricity_Transition_Project.html",
    "title": "Swiss Electricity System Under Transition",
    "section": "",
    "text": "Switzerland stands at a turning point in its energy transition. With a national policy to phase out nuclear power by 2050, and growing urgency around climate change, the country faces a critical challenge:\n\nCan it maintain energy security while transitioning to a renewable electricity system?\n\nWhat began as a data-driven exploration of Swiss energy production soon evolved into a focused investigation of one key question:\nCan solar photovoltaic (PV) energy scale enough to replace nuclear power?\nThis report combines exploratory data analysis, a study of solar output vs. radiation patterns, and a forward-looking scenario :\n\nWill Switzerland be able to replace nuclear power with solar, or will it need to rely on imports, hydro expansion, and storage?"
  },
  {
    "objectID": "standalone-projects/swiss_electricity_transition_R/Swiss_Electricity_Transition_Project.html#preface",
    "href": "standalone-projects/swiss_electricity_transition_R/Swiss_Electricity_Transition_Project.html#preface",
    "title": "Swiss Electricity System Under Transition",
    "section": "",
    "text": "Switzerland stands at a turning point in its energy transition. With a national policy to phase out nuclear power by 2050, and growing urgency around climate change, the country faces a critical challenge:\n\nCan it maintain energy security while transitioning to a renewable electricity system?\n\nWhat began as a data-driven exploration of Swiss energy production soon evolved into a focused investigation of one key question:\nCan solar photovoltaic (PV) energy scale enough to replace nuclear power?\nThis report combines exploratory data analysis, a study of solar output vs. radiation patterns, and a forward-looking scenario :\n\nWill Switzerland be able to replace nuclear power with solar, or will it need to rely on imports, hydro expansion, and storage?"
  },
  {
    "objectID": "standalone-projects/swiss_electricity_transition_R/Swiss_Electricity_Transition_Project.html#introduction",
    "href": "standalone-projects/swiss_electricity_transition_R/Swiss_Electricity_Transition_Project.html#introduction",
    "title": "Swiss Electricity System Under Transition",
    "section": "Introduction",
    "text": "Introduction\nSwitzerland’s electricity mix is unique in Europe, with a strong reliance on hydropower and a legacy of nuclear energy. This has enabled the country to maintain a low-carbon electricity system for decades.\nHowever, under the Swiss Energy Strategy 2050, the government plans to phase out nuclear energy and significantly increase the share of renewables - especially solar power.\nThis report investigates whether this transition is technically feasible, focusing on three key questions:\n\nHow does Switzerland currently produce electricity, and how does this vary seasonally?\nWhat is the real potential of solar PV, given seasonal variation in sunlight?\nCan solar realistically replace nuclear capacity, or will Switzerland depend on imports and hydro?\n\nWe use data from 2020 to 2024 - the period when Switzerland began officially recording renewable production - to assess energy dynamics, simulate future scenarios, and evaluate feasibility.\n\n\n\n\n\n\nNoteWhy Start in 2020?\n\n\n\n\n\nSwitzerland began systematically reporting renewable energy production in monthly detail starting in 2020. As such, this year marks the most reliable starting point for consistent renewable energy tracking in the Swiss energy system.\n\n\n\n\n\n\n\n\n\nNoteWhy We Focus on Solar and Nuclear\n\n\n\n\n\nHydro power contributes over 50% of Switzerland’s electricity today, but expanding it further is challenging due to ecological protections, geographic limitations, and social resistance to large infrastructure projects.\nAs a result, this analysis focuses on the evolving relationship between solar energy and nuclear phase-out, while treating hydro as a relatively stable, non-expanding baseline."
  },
  {
    "objectID": "standalone-projects/swiss_electricity_transition_R/Swiss_Electricity_Transition_Project.html#data-sources-metadata",
    "href": "standalone-projects/swiss_electricity_transition_R/Swiss_Electricity_Transition_Project.html#data-sources-metadata",
    "title": "Swiss Electricity System Under Transition",
    "section": "Data Sources & Metadata",
    "text": "Data Sources & Metadata\nThis appendix provides detailed metadata for the datasets used in this analysis. Each table is shown in a scrollable box to keep the layout compact.\n\nEnergy data (Swiss Federal Office of energy): Monthly Energy Production (hydro, nuclear, solar, etc.).\n\n\n\n\n\n\n\nNoteClick to expand: Metadata for Monthly Production Dataset\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMetadata: Monthly Energy Production (Switzerland)\n\n\nVariable\nDescription\nSource\nUnit\n\n\n\n\ndate_month\nMonthly timestamp (first day of each month, parsed from multilingual date string)\nSwiss Federal Office of Energy (SFOE)\nYYYY-MM-DD\n\n\ndate_label\nMonth label in short format (e.g., Jan-2020) for plotting or reporting\nSwiss Federal Office of Energy (SFOE)\nstring\n\n\nhydroelectric\nMonthly electricity production from hydroelectric sources (in GWh)\nSwiss Federal Office of Energy (SFOE)\nGWh\n\n\nnuclear\nMonthly electricity production from nuclear power plants (in GWh)\nSwiss Federal Office of Energy (SFOE)\nGWh\n\n\nthermic_clasique\nElectricity production from classic thermal (fossil fuel-based) sources (in GWh)\nSwiss Federal Office of Energy (SFOE)\nGWh\n\n\nthermic_renewable\nElectricity production from renewable thermal sources (e.g., biogas, waste) (in GWh)\nSwiss Federal Office of Energy (SFOE)\nGWh\n\n\nwind_thurbine\nElectricity generated from wind turbines (in GWh)\nSwiss Federal Office of Energy (SFOE)\nGWh\n\n\nphotovoltaic\nElectricity produced from photovoltaic (solar) sources (in GWh)\nSwiss Federal Office of Energy (SFOE)\nGWh\n\n\ntotal\nTotal electricity production from all sources (hydro, nuclear, thermal, renewables) (in GWh)\nSwiss Federal Office of Energy (SFOE)\nGWh\n\n\nacumulation_pumping\nElectricity used for pumping water into accumulation lakes (in GWh, i.e., storage)\nSwiss Federal Office of Energy (SFOE)\nGWh\n\n\nnet_production\nNet electricity production (total production - pumping/storage use) (in GWh)\nSwiss Federal Office of Energy (SFOE)\nGWh\n\n\nimport\nGross imports of electricity from neighboring countries (in GWh)\nSwiss Federal Office of Energy (SFOE)\nGWh\n\n\nexport\nGross exports of electricity to neighboring countries (in GWh)\nSwiss Federal Office of Energy (SFOE)\nGWh\n\n\ncountry_consumtion\nTotal electricity used domestically, including grid and industrial use (in GWh)\nSwiss Federal Office of Energy (SFOE)\nGWh\n\n\nlosses\nGrid losses (distribution/transmission) (in GWh)\nSwiss Federal Office of Energy (SFOE)\nGWh\n\n\nfinal_consumtion\nFinal consumption by Swiss end users (households, services, industry) (in GWh)\nSwiss Federal Office of Energy (SFOE)\nGWh\n\n\nexport_import\nNet importer/exporter status (1 = net importer, 0 = net exporter)\nSwiss Federal Office of Energy (SFOE)\nbinary (0/1)\n\n\n\n\n\n\n\n\n\n\n\n\nMeteoSwiss OGD-NBCN: Monthly Solar Irradiation.\n\n\n\n\n\n\n\nNoteClick to expand: Metadata for Monthly Solar Irradiation Dataset\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMetadata: Solar Radiation (MeteoSwiss Aggregated Data)\n\n\nVariable\nDescription\nSource\nprocessing_steps\nUnit\n\n\n\n\ndate_month\nFirst day of each month (used as timestamp for monthly aggregated data)\nmeteoswiss.ch\nDates represent the aggregation level (monthly); derived from daily values\nYYYY-MM-DD\n\n\nglobal_radiation\nMonthly average global solar radiation across all Swiss MeteoSwiss stations (in MJ/m²)\nmeteoswiss.ch\nDownloaded monthly global radiation values from multiple stations; averaged across stations per month\nMJ/m²\n\n\n\n\n\n\n\n\n\n\n\n\nBoth data sets are aggregated to monthly frequency and merged on a monthly date column.\n\n\nEnergy data (Swiss Federal Office of energy): Swiss Nuclear Power Plants Dataset.\n\n\n\n\n\n\n\nNoteClick to expand: Metadata for Nuclear Production Dataset\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMetadata: Swiss Nuclear Power Plants Dataset\n\n\nVariable\nDescription\n\n\n\n\nyear\nCalendar year\n\n\nbeznau1_production_gwh\nBeznau I: Annual energy production (GWh)\n\n\nbeznau1_capacity_mwe\nBeznau I: Installed capacity (MWe)\n\n\nbeznau1_util_pct\nBeznau I: Capacity utilization rate (%)\n\n\nbeznau2_production_gwh\nBeznau II: Production (GWh)\n\n\nbeznau2_capacity_mwe\nBeznau II: Capacity (MWe)\n\n\nbeznau2_util_pct\nBeznau II: Utilization (%)\n\n\nmuhleberg_production_gwh\nMühleberg: Production (GWh)\n\n\nmuhleberg_capacity_mwe\nMühleberg: Capacity (MWe)\n\n\nmuhleberg_util_pct\nMühleberg: Utilization (%)\n\n\ngosgen_production_gwh\nGösgen: Production (GWh)\n\n\ngosgen_capacity_mwe\nGösgen: Capacity (MWe)\n\n\ngosgen_util_pct\nGösgen: Utilization (%)\n\n\nleibstadt_production_gwh\nLeibstadt: Production (GWh)\n\n\nleibstadt_capacity_mwe\nLeibstadt: Capacity (MWe)\n\n\nleibstadt_util_pct\nLeibstadt: Utilization (%)\n\n\ntotal_production_gwh\nSum of all reactors’ production (GWh)\n\n\ntotal_capacity_mwe\nSum of installed capacities (MWe)\n\n\ntotal_util_pct\nAggregate capacity utilization (%, rough)"
  },
  {
    "objectID": "standalone-projects/swiss_electricity_transition_R/Swiss_Electricity_Transition_Project.html#energy-production-20202024",
    "href": "standalone-projects/swiss_electricity_transition_R/Swiss_Electricity_Transition_Project.html#energy-production-20202024",
    "title": "Swiss Electricity System Under Transition",
    "section": "Energy Production (2020–2024)",
    "text": "Energy Production (2020–2024)\nSwitzerland began consistently recording monthly renewable energy production in 2020, providing a solid foundation for analyzing how the country generates electricity across sources and seasons.\nThis section explores production from hydroelectric, nuclear, solar, thermal (classic and renewable), and wind sources using monthly data from 2020 to mid-2025. The goal is to understand:\n\nHow electricity production is distributed across sources\nHow seasonality affects each energy type\nWhat happens to nuclear output when renewables peak\nHow pumped storage is used to balance the grid\n\nThese dynamics set the stage for assessing whether solar energy can realistically scale to replace nuclear output in the coming decades.\n\nMonthly Energy Production in Switzerland\nThe chart below shows monthly electricity generation by energy type, from January 2020 to May 2025. Each color band represents a specific energy source.\nAdditional features:\n\nA red line shows net production (after subtracting pumped storage use)\nGrey bars below zero represent electricity used for pumped storage (i.e., storing excess electricity by pumping water uphill)\n\n\n\n\n\n\n\n\n\n\n\nHydroelectric power shows a strong seasonal pattern, peaking between May and August due to snowmelt and rainfall.\nNuclear energy remains relatively stable but shows regular dips around May–June, corresponding with planned maintenance.\nSolar output is strongly seasonal, increasing during spring and peaking in summer.\nThermal production (classic and renewable) remains steady throughout the year.\nWind power contributes very little to the energy mix.\nPumped storage usage (grey bars) increases during high-production periods - storing surplus electricity for later use.\nThe net production line reflects how pumped storage smooths out seasonal volatility in supply.\n\nTogether, these patterns highlight Switzerland’s ability to dynamically balance its energy system - a vital feature as the country phases out stable nuclear baseload.\n\n\nAverage Share of Energy Production (2020–2024)\n\n\nThe table on the right shows the average share of each energy source in Switzerland’s electricity mix over the five-year period:\nHydroelectric power is clearly dominant, providing over half of the country’s electricity. Nuclear remains significant at over a quarter, while solar - despite rapid growth - still accounts for just 5.2% of the total mix.\nThermal sources together contribute around 15%, and wind power remains negligible.\n\n\n\n\n\n\n\n\n\nAvg. Share of Production (2020–2024)\n\n\nEnergy Type\nAvg. Share (%)\n\n\n\n\nHydroelectric\n51.5\n\n\nNuclear\n28.3\n\n\nThermal (Classic)\n10.1\n\n\nSolar\n5.2\n\n\nThermal (Renewable)\n4.8\n\n\nWind\n0.2\n\n\n\n\n\n\n\n\n\n\n\nSeasonality of Energy Production\nTo better understand how Switzerland’s electricity mix changes over time, we visualize each energy source’s monthly share of total production, rather than absolute values.\nThis approach helps uncover:\n\nSeasonal trends\nTrade-offs between energy types (e.g., hydro vs. nuclear)\nComplementarity between renewables\n\nThe chart below shows monthly percentage shares for each production type from January 2020 to mid-2025.\n\n\n\n\n\n\n\n\n\nThe chart shows that:\n\nHydroelectric (red line) shows a strong and consistent seasonal pattern:\n\nPeaks in late spring to early summer (May–July)\nDrops in autumn and winter, especially December–February\n\nNuclear (gold line) behaves in an inverse seasonal pattern:\n\nMost stable across months, but shows predictable dips in May–June, corresponding with scheduled maintenance outages\nThese dips are well-aligned with hydro and solar peaks, indicating planned coordination\n\nSolar (cyan line) rises steadily from March, peaking in June–July, then drops in autumn and nearly vanishes in December–January.\nThermal (classic and renewable) sources remain relatively flat and act as baseline supplements, especially in winter.\nWind contributes a negligible share, fluctuating around 0.2% with no clear seasonal pattern.\n\nOverall, the chart illustrates a deliberate balancing strategy:\n\nSwitzerland reduces nuclear output when renewable supply increases, especially in summer.\nThis modulation enhances grid flexibility, an essential feature as the country prepares to phase out nuclear energy\n\n\n\nCorrelation Between Energy Sources\nThe seasonal analysis suggested that nuclear production often declines when renewable output (hydro and solar) increases. To test this relationship more formally, we calculate Pearson correlation coefficients between monthly shares of:\n\nHydroelectric vs. Nuclear\nSolar vs. Nuclear\n\nWhy do this?\nCorrelation helps quantify the degree of inverse movement between sources. If two sources are strongly negatively correlated, it means when one rises, the other tends to fall - suggesting substitution or balancing behavior.\nFor Switzerland, this matters because:\n\nIf nuclear consistently steps down when renewables rise, it shows the grid is already designed to integrate renewables without overcapacity.\n\nIt also highlights how nuclear provides flexibility today, which will need to be replaced by other mechanisms (imports, storage, or flexible hydro) after the phase-out.\n\n\n\n\n\n\n\n\n\nSource Pair\nPearson Correlation\n\n\n\n\nHydroelectric vs Nuclear\n−0.774\n\n\nSolar vs Nuclear\n−0.566\n\n\n\n\n\n\n\nThe results confirm our observations:\n\nHydroelectric vs. Nuclear:\nA strong negative correlation (r = -0.774).\nWhen hydro production increases in spring and summer, nuclear output reliably decreases - mainly due to planned maintenance and grid balancing.\nSolar vs. Nuclear:\nA moderate negative correlation (r = -0.566).\nSolar output is still a smaller share of the mix than hydro, but the inverse relationship suggests nuclear is also adjusted downward during solar peaks.\n\nIn short, Switzerland’s nuclear fleet already functions as a flexible buffer against seasonal renewable fluctuations.\nReplacing this role will be a major challenge post-2050, as solar and hydro cannot “self-balance” without external support (imports, long-duration storage, or expanded hydro flexibility).\n\n\n\n\n\n\nNotePlanned Nuclear Maintenance and Seasonal Renewables\n\n\n\n\n\nSwiss nuclear plants typically undergo annual inspections and fuel replacement in late spring to early summer. This timing aligns with peak hydro and solar output, allowing nuclear capacity to temporarily decrease without compromising grid stability. This synergy reflects how Switzerland already leverages seasonal renewables to reduce nuclear reliance. This pattern will become increasingly critical as the phase-out proceeds.\nSource: ENSI – Operation of Nuclear Power Plants\n\n\n\n\n\nNuclear Power Plants Overview\nNuclear energy has been a cornerstone of Switzerland’s electricity system for decades, providing stable, low-carbon baseload power. Today, the country operates four reactors across three sites:\n\nBeznau I & II (Aargau) - the world’s oldest commercial reactors still in operation.\nGösgen (Solothurn).\nLeibstadt (Aargau).\n\nThe Mühleberg plant (Bern) was permanently decommissioned in December 2019, becoming the first Swiss nuclear reactor to shut down.\nBetween 2020 and 2024, nuclear contributed on average 22,190 GWh, representing between 28.4% (2024) and 35.8% (2022) of Switzerland’s total electricity production.\nSwitzerland has decided on a gradual nuclear phase-out, meaning no new reactors will be built, but the existing plants can continue operating as long as they remain safe.\n\n\nGeographic Overview\nThe map below shows the locations and status of Swiss nuclear power plants.\n\nGreen markers: operational reactors\nRed markers: decommissioned sites\n\nHovering over a site displays details on average production (2020–2024), canton, and operational history.\n\n\n\n\n\n\nNote: Coordinates for the nuclear power plants were obtained from public sources1:\n\n\n\n\n\n\nNoteNuclear Phase-Out Policy\n\n\n\n\n\nUnder the Swiss Energy Strategy 2050, no new nuclear plants will be constructed.\nExisting plants can continue operating indefinitely, provided safety is guaranteed.\nThis flexible phase-out contrasts with some countries (e.g., Germany), where fixed shutdown dates were set."
  },
  {
    "objectID": "standalone-projects/swiss_electricity_transition_R/Swiss_Electricity_Transition_Project.html#photovoltaic-performance-and-solar-radiation",
    "href": "standalone-projects/swiss_electricity_transition_R/Swiss_Electricity_Transition_Project.html#photovoltaic-performance-and-solar-radiation",
    "title": "Swiss Electricity System Under Transition",
    "section": "Photovoltaic Performance and Solar Radiation",
    "text": "Photovoltaic Performance and Solar Radiation\nSwitzerland has expanded its installed solar PV capacity rapidly in recent years. However, raw production values reflect both:\n\nGrowing infrastructure (more panels installed)\n\nNatural variation in solar radiation (seasonal cycles, weather)\n\nTo isolate how much solar performance depends on sunlight rather than capacity growth,we compare solar production with measured solar radiation between 2020 and 2024.\n\nMethod: STL Decomposition\nWe apply STL decomposition (Seasonal-Trend decomposition using LOESS) to photovoltaic production:\n\nTrend: captures the long-term growth in installed PV capacity\nSeasonal: captures regular annual cycles (sunlight availability)\nRemainder: captures short-term variation and anomalies\n\nBy recombining the seasonal + remainder components, we obtain a normalized PV output — representing solar generation patterns independent of capacity growth.\n\n\n\n\n\nSTL decomposition of monthly photovoltaic production, showing trend, seasonal cycle, and remainder.\n\n\n\n\n\n\nComparison: Solar Radiation vs Normalized PV Output\nThe figure below compares normalized PV output (MWh) to measured solar radiation (MJ/m²). A dual-axis plot aligns the two series, making their seasonal co-movement visible.\n\n\n\n\n\n\n\n\n\n\n\nCorrelation Analysis\nTo quantify this relationship, we compute the Pearson correlation coefficient between:\n\nNormalized PV output, and\nMeasured solar radiation\n\n\nThe resulting correlation is: 0.896.\n\nAs expected this indicates:\n- This very strong positive correlation shows that solar PV production is tightly coupled to radiation availability.\n- Seasonal radiation patterns, not infrastructure, explain the shape of PV output.\n- Capacity growth only scales the curve upwards — it does not change the fundamental seasonal imbalance.\n\n\nSeasonal Distribution of PV Energy Production\nWhen averaged across 2020–2024, the seasonal breakdown of PV output is:\n\nWinter (Dec–Feb): 8.3%\n\nSpring (Mar–May): 31.6%\n\nSummer (Jun–Aug): 40.8%\n\nAutumn (Sep–Nov): 19.3%\n\nThese numbers are telling us that:\n\nProduction is heavily concentrated in summer (nearly half of annual PV output).\nWinter output is very limited, despite being the period of highest demand (heating + low daylight).\nThis seasonal mismatch is the core structural challenge for replacing nuclear with solar.\n\n\n\nPV Contribution Over Time\n\n\nSwitzerland’s photovoltaic (PV) generation has grown rapidly in recent years.To illustrate this trend, we track annual PV production (GWh) and its share of total electricity production from 2020 to 2024.\nThe chart shows steady year-on-year growth, with no reversals.\nThis suggests strong policy and market momentum supporting PV expansion.\nYet, even with this rapid growth:\n\nPV accounted for only ~7.4% of Switzerland’s electricity in 2024\nNuclear, by contrast, still supplied ~28% over the same period\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nForecasting Solar PV Production (2025–2030)\nIn this section, we use time series modeling to forecast monthly solar PV production in Switzerland from 2025 to 2030, based on trends observed between 2020 and mid-2025.\nMethodology\nWe use an ARIMA (Auto-Regressive Integrated Moving Average) model, a widely used statistical technique for modeling time series data. This model captures:\n\nTrend (long term increase in PV output due to growning Installations)\nSeasonality (cyclical patterns due to solar radiation patterns)\nShort-term dependencies (month to month autocorrelation in output)\n\nAssumptions\nThis forecast is based on the critical assumptions that the PV capacity conitnues to grow at a similar pace as observed in 2020 to mid 2025.\nThe model does not account for:\n\nPolicy changes,\nSupply chain disruptions,\nTechnological breakthroughs,\nAccelerated or stalled installation rates.\n\nIt is a s trend projection, with no technical potential simulation or policy scenarios.\n\n\nInterpretation:\n\nThe seasonality is clearly preserved in the forecast: output peaks in summer (May–July) and drops in winter (December–January).\nThe amplitude of production increases over time, consistent with observed growth in installed capacity.\nby 2030 the PV production can peak to 1600 Ghw during the summer months, potentially being able to supply over 10 TWh/year.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNoteWhat Do the Confidence Intervals Mean?\n\n\n\n\n\nThe shaded ribbons around the forecast represent confidence intervals:\n\n80% interval (darker blue): there’s an 80% chance the true value falls inside.\n95% interval (lighter blue): there’s a 95% chance the true value falls inside.\n\nThese intervals widen over time to reflect increasing uncertainty in long-term forecasts.\n\n\n\n\n\nGrowth vs. Nuclear Comparison\nAt the current pace (~1 TWh added annually), Switzerland would need about 22 years to scale PV production enough to match the annual nuclear output (≈22–23 TWh).\nHowever, this projection assumes:\n\nLinear growth (no acceleration or policy-driven scale-up)\nNo seasonal adjustment (ignores the winter shortfall identified earlier)\n\nIn reality, scaling PV alone is insufficient: seasonal storage, imports, and flexible hydro will be essential to cover winter deficits.\n\n\n\n\n\n\nNoteWhy Annual Growth is Misleading\n\n\n\n\n\nAnnual growth rates can create the illusion that solar can fully replace nuclear. But electricity systems are seasonal, not annual.\nEven if PV reaches 22–23 TWh/year, the winter contribution will remain very small.\nThus, the transition challenge is not just about producing “enough” yearly solar - it’s about producing it when it’s needed most."
  },
  {
    "objectID": "standalone-projects/swiss_electricity_transition_R/Swiss_Electricity_Transition_Project.html#electricity-imports-exports-grid-balance",
    "href": "standalone-projects/swiss_electricity_transition_R/Swiss_Electricity_Transition_Project.html#electricity-imports-exports-grid-balance",
    "title": "Swiss Electricity System Under Transition",
    "section": "Electricity Imports, Exports & Grid Balance",
    "text": "Electricity Imports, Exports & Grid Balance\nSwitzerland operates one of Europe’s most reliable electricity systems. This reliability depends not only on domestic production but also on cross-border electricity flows, which help balance seasonal supply and demand.\nIn this section, we examine how Switzerland balances its grid by looking at:\n\nThe overall balance of production, imports, and consumption\nSeasonal patterns in imports and exports\nThe implications of losing stable nuclear generation\n\n\nGrid Balance Check\nWe verify whether Switzerland’s electricity system is operationally balanced using the identity:\nGrid Balance = (Net Production + Imports) – (Exports + Consumption)\nThe balance equals zero in all months, confirming that the Swiss grid is consistently balanced - total inflows match total outflows.\nThis highlights Switzerland’s strong integration with the European grid and its ability to maintain operational stability.\n\n\nAverage Net Electricity Imports by Month (2020–2024)\nThe figure below shows average monthly net imports (exports-imports), averaged across 2020–2024:\n\nPositive values = Net Export\nNegative values = Net Import\n\n\n\nWinter (Dec–Feb): Switzerland is a net importer of electricity, reflecting higher demand and limited solar output.\nSpring and Summer (Apr–Aug): The country becomes a net exporter, supported by strong hydroelectric flows and solar generation.\nAutumn (Sep–Nov): The balance moves closer to zero, with mixed import/export activity.\nThis seasonal pattern confirms Switzerland’s reliance on imports during winter deficits, while acting as a net exporter during periods of renewable abundance.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhy Imports Will Matter\nToday, nuclear power provides stable year-round baseload, covering winter demand when solar is minimal. With nuclear gradually phased out:\n\nWinter deficits will deepen (solar provides only ~8.3% of annual output in winter vs ~40.8% in summer).\nHydropower cannot fully compensate, as its seasonal peaks align with summer.\nImports will become increasingly critical for:\n\nSecurity of supply\nGrid stability\nMarket integration with neighboring countries"
  },
  {
    "objectID": "standalone-projects/swiss_electricity_transition_R/Swiss_Electricity_Transition_Project.html#replacing-nuclear-with-solar-feasibility-and-limitations",
    "href": "standalone-projects/swiss_electricity_transition_R/Swiss_Electricity_Transition_Project.html#replacing-nuclear-with-solar-feasibility-and-limitations",
    "title": "Swiss Electricity System Under Transition",
    "section": "Replacing Nuclear with Solar: Feasibility and Limitations",
    "text": "Replacing Nuclear with Solar: Feasibility and Limitations\nTo test whether solar could fully replace nuclear energy, we simulate a nuclear-free Swiss grid where:\n\nNuclear production (~22–23 TWh/year) is removed.\nSolar PV is scaled up to ~28 TWh/year (≈ nuclear + current PV), distributed monthly based on real PV production profiles (2020–2024).\nHydroelectric, thermal, and wind remain fixed at their 2020–2024 averages.\nImports are excluded at first, to reveal the true domestic balance.\n\nThis scenario represents a simple “solar-for-nuclear substitution” without assuming additional hydro expansion, storage, or demand-side flexibility, second and tertiary reserves, etc.\n\nWinter Gaps Without Nuclear\n\n\nIn this scenario, domestic production falls short of consumption by up to 2.1 TWh in December and 1.7 TWh in January. Across the winter months (Nov–Feb), the total deficit reaches ~5.7 TWh.\nBy contrast, summer months (May–Aug) show large surpluses of ~13 TWh, underscoring the structural seasonal mismatch.\nThe chart reinforces the conclusion:\n\nsolar can match nuclear’s annual output,\nbut not its seasonal reliability.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImports as one of the Balancing Mechanism\nSwitzerland already relies on imports in winter and exports in summer to balance its grid. In a nuclear-free system, this reliance would increase sharply, with imports becoming the primary tool for covering winter deficits.\n\n\nThe chart on the right illustrates this point: imports (orange bars) rise steeply in December–February, while in May–August solar and hydro surpluses reduce the need for imports.\nWhile technically feasible thanks to Switzerland’s strong interconnections with neighboring countries, this dependence raises key risks:\n\nEnergy security: reliance on France, Germany, and Italy during critical months.\nMarket volatility: higher price exposure if Europe faces simultaneous winter shortages.\nGeopolitical exposure: reduced autonomy when neighboring systems are also under pressure."
  },
  {
    "objectID": "standalone-projects/swiss_electricity_transition_R/Swiss_Electricity_Transition_Project.html#conclusion",
    "href": "standalone-projects/swiss_electricity_transition_R/Swiss_Electricity_Transition_Project.html#conclusion",
    "title": "Swiss Electricity System Under Transition",
    "section": "Conclusion",
    "text": "Conclusion\nThis analysis shows that while solar can replace nuclear in annual totals, it cannot guarantee seasonal reliability. Without nuclear, Switzerland faces deficits of ~5–6 TWh in winter (Nov–Feb) and surpluses of ~13 TWh in summer.\nToday, imports already bridge these gaps. In a nuclear-free future, however, imports would become the backbone of winter security. While technically feasible, this creates dependence on neighboring systems (France, Germany, Italy) and heightens exposure to market volatility and geopolitical risks.\nAt the same time, Switzerland is investing in domestic balancing solutions:\n\nPumped-storage: the 900 MW Nant de Drance plant came online in 20222, offering capacity comparable to a nuclear reactor such as Gösgen. Further projects are under study in the Grimsel region3.\nBattery storage: projects such as Alpiq’s Gondo and Lausanne batteries demonstrate the growing role of short-term flexibility4.\nSolar expansion: according to Energie Zukunft Schweiz, Switzerland has a technical PV potential of 9–11 GW5. Unlocking this potential requires stronger political and regulatory frameworks. In parallel, federal studies suggest that ~6% of Swiss land area is suitable for PV6, though deployment faces constraints from heritage protection and land-use policies.\nSmart-grid upgrades: ongoing digitalization projects aim to improve flexibility, demand management, and grid resilience7.\n\nSwitzerland’s energy transition is therefore not just about adding solar capacity. It is a system challenge: aligning seasonal production with demand, balancing imports with domestic flexibility, and integrating storage and smart-grid technology.\nThe path forward will require a portfolio approach:\n\nSeasonal imports (short- to medium-term necessity)\nExpansion of solar and flexible hydropower\nLong-duration storage (pumped-hydro, future technologies)\nSmart grids and efficiency gains\n\nUltimately, success will not be measured by annual generation totals, but by ensuring secure electricity supply in winter, when the system is under the greatest strain."
  },
  {
    "objectID": "standalone-projects/swiss_electricity_transition_R/Swiss_Electricity_Transition_Project.html#footnotes",
    "href": "standalone-projects/swiss_electricity_transition_R/Swiss_Electricity_Transition_Project.html#footnotes",
    "title": "Swiss Electricity System Under Transition",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nCoordinates for nuclear power plants in Switzerland: Beznau, Gösgen, Leibstadt, and Mühleberg.↩︎\nNant de Drance SA – The power plant↩︎\nKWO (Kraftwerke Oberhasli AG) – Projects↩︎\nAlpiq – Battery storage in Lausanne↩︎\nPotential PV↩︎\nArticle - New Federal Study↩︎\nSFOE – Smart grid updates↩︎"
  },
  {
    "objectID": "standalone-projects/index.html",
    "href": "standalone-projects/index.html",
    "title": "Standalone Projects",
    "section": "",
    "text": "This section includes analytical projects that are not strictly machine learning models but still demonstrate data science and applied research skills.\nCurrent projects:\n\nBitcoin & Portfolio Analysis (R)\nSwiss Energy Production and Solar Radiation (R)",
    "crumbs": [
      "Home",
      "Standalone Projects",
      "Overview"
    ]
  },
  {
    "objectID": "ml-portfolio/index.html",
    "href": "ml-portfolio/index.html",
    "title": "Machine Learning Portfolio",
    "section": "",
    "text": "This section presents machine learning work developed in R and Python.\nProjects included:\n\nR Labs (example: SVM on iris)\nNHANES health analysis in R (regression + SVM)\nDiabetes readmission prediction in Python (end-to-end pipeline)\n\nMore projects will be added as the MSc program continues.",
    "crumbs": [
      "Home",
      "ML Portfolio",
      "Overview"
    ]
  },
  {
    "objectID": "ml-portfolio/02_nhanes_R/index.html",
    "href": "ml-portfolio/02_nhanes_R/index.html",
    "title": "NHANES Project (R)",
    "section": "",
    "text": "This section will host the NHANES health analysis project, including regression models, classification, and data exploration.\nContent will be added soon.",
    "crumbs": [
      "Home",
      "ML Portfolio",
      "NHANES - R Project"
    ]
  },
  {
    "objectID": "ml-portfolio/02_nhanes_R/01_linear_model.html",
    "href": "ml-portfolio/02_nhanes_R/01_linear_model.html",
    "title": "Linear Regression Analysis - Predicting Body Mass Index",
    "section": "",
    "text": "The goal is to explain wich factors are associated with BMI in US adults (NHANES dataset), controling for demographics (age, gender, race, education), socio-economic indicators (education, income) and lifestyle (sleep, physical activity, alcohol, smoking). We will start simple and incrementally extend to a multiple linear regression, also adding multiple regression effects that are conditional on the other covariates in the model.\n\n\nBody Mass Index (BMI) is a continuous variable calculated as weight (kg) divided by height squared (\\(m^{2}\\)). BMI is a proxy for body fat and is strongly related to chronic diseases such as diabetes, cardiovascular disease and hypertension.\nIn this analysis, we use NHANES adult participants (Age &gt;= 18) to examine how demographics, socioeconomic status and lifestyle behaviors are associated withBMI\n\n\n\nWe model BMI as a linear function of selected predictors:\nBMI = \\(\\beta_0\\) + \\(\\beta_1\\) * Age + \\(\\beta_2\\) * Gender + \\(\\beta_3\\) * Race + \\(\\beta_4\\) * Education + \\(\\beta_5\\) * log(Income) + \\(\\beta_6\\) * PhysActive + \\(\\beta_7\\) * SleepHrs + \\(\\beta_8\\) * SmokeNow + \\(\\beta_8\\) * AlcoholDay + \\(\\epsilon\\)\nWhere:\n\n\\(\\beta_0\\) is the intercept (BMI)\n\\(\\beta_1\\)…\\(\\beta_8\\) are the regression coefficients representing the effect on each predictor.\n\\(\\epsilon\\) represents the random error term (assumed that it is normally distributed)\n\n\n\n\n\nAfter adjusting for covariates, how does BMI vary with Age?\nDo demographic factors (Gender, Race, Education) show overall association with BMI?\nAre lifestyle factors (PsyActive, AlcoholDay, SleepNight, SmokeNow) associated with BMI, and how much?\nHow much variance is explained by the model?",
    "crumbs": [
      "Home",
      "ML Portfolio",
      "NHANES - R Project",
      "Linear Regression Analysis - Predicting Body Mass Index"
    ]
  },
  {
    "objectID": "ml-portfolio/02_nhanes_R/01_linear_model.html#introduction-to-linear-modeling",
    "href": "ml-portfolio/02_nhanes_R/01_linear_model.html#introduction-to-linear-modeling",
    "title": "Linear Regression Analysis - Predicting Body Mass Index",
    "section": "",
    "text": "The goal is to explain wich factors are associated with BMI in US adults (NHANES dataset), controling for demographics (age, gender, race, education), socio-economic indicators (education, income) and lifestyle (sleep, physical activity, alcohol, smoking). We will start simple and incrementally extend to a multiple linear regression, also adding multiple regression effects that are conditional on the other covariates in the model.\n\n\nBody Mass Index (BMI) is a continuous variable calculated as weight (kg) divided by height squared (\\(m^{2}\\)). BMI is a proxy for body fat and is strongly related to chronic diseases such as diabetes, cardiovascular disease and hypertension.\nIn this analysis, we use NHANES adult participants (Age &gt;= 18) to examine how demographics, socioeconomic status and lifestyle behaviors are associated withBMI\n\n\n\nWe model BMI as a linear function of selected predictors:\nBMI = \\(\\beta_0\\) + \\(\\beta_1\\) * Age + \\(\\beta_2\\) * Gender + \\(\\beta_3\\) * Race + \\(\\beta_4\\) * Education + \\(\\beta_5\\) * log(Income) + \\(\\beta_6\\) * PhysActive + \\(\\beta_7\\) * SleepHrs + \\(\\beta_8\\) * SmokeNow + \\(\\beta_8\\) * AlcoholDay + \\(\\epsilon\\)\nWhere:\n\n\\(\\beta_0\\) is the intercept (BMI)\n\\(\\beta_1\\)…\\(\\beta_8\\) are the regression coefficients representing the effect on each predictor.\n\\(\\epsilon\\) represents the random error term (assumed that it is normally distributed)\n\n\n\n\n\nAfter adjusting for covariates, how does BMI vary with Age?\nDo demographic factors (Gender, Race, Education) show overall association with BMI?\nAre lifestyle factors (PsyActive, AlcoholDay, SleepNight, SmokeNow) associated with BMI, and how much?\nHow much variance is explained by the model?",
    "crumbs": [
      "Home",
      "ML Portfolio",
      "NHANES - R Project",
      "Linear Regression Analysis - Predicting Body Mass Index"
    ]
  },
  {
    "objectID": "ml-portfolio/02_nhanes_R/01_linear_model.html#data-processing",
    "href": "ml-portfolio/02_nhanes_R/01_linear_model.html#data-processing",
    "title": "Linear Regression Analysis - Predicting Body Mass Index",
    "section": "2 Data processing",
    "text": "2 Data processing\n\nPopulation: NHANES adults (Age \\(\\geqslant\\) 18).\nVariables: Age; Gender; Race1; Education; HHIncomeMid (we used log transform); PhysActive; SleepHrsNight; AlcoholDay; SmokeNow; BPSysAve. Factor coding: treatment contrasts (reference vs others).\nMissing data strategy (baseline): Complete-case analysis on these variables to keep the workflow transparent.\n\n\n\n\n\n\n\nNoteHandling Missing Values\n\n\n\n\n\nWe included only adults (≥ 18 years). BMI in children is interpreted with age- and sex-specific percentiles, so combining adults and minors would yield non-comparable BMI categories and biased estimates. We created log_income = log(HHIncomeMid). We then used a complete-case dataset for baseline modeling (all variables observed), retaining 27.5% of the adult sample.\nAlcoholDay/SmokeNow are driving most most of the loss.\n\n\n\nPercentage of Missing Values\n\n\nVariable\nPercent_Missing\n\n\n\n\nSmokeNow\n57.1\n\n\nAlcoholDay\n34.3\n\n\nHHIncomeMid\n8.6\n\n\nlog_income\n8.6\n\n\nBPSysAve\n3.7\n\n\nEducation\n3.5\n\n\nBMI\n0.9\n\n\nSleepHrsNight\n0.2\n\n\nAge\n0.0\n\n\nRace1\n0.0\n\n\nGender\n0.0\n\n\nPhysActive\n0.0",
    "crumbs": [
      "Home",
      "ML Portfolio",
      "NHANES - R Project",
      "Linear Regression Analysis - Predicting Body Mass Index"
    ]
  },
  {
    "objectID": "ml-portfolio/02_nhanes_R/01_linear_model.html#exploratory-analysis-eda",
    "href": "ml-portfolio/02_nhanes_R/01_linear_model.html#exploratory-analysis-eda",
    "title": "Linear Regression Analysis - Predicting Body Mass Index",
    "section": "3 Exploratory Analysis (EDA)",
    "text": "3 Exploratory Analysis (EDA)\n\n3.1 Outcome distribution (BMI)\n\n\nSummary statistics: mean, median, SD, quantiles:\nThe response variable, Body Mass Index (BMI), ranged from 15.0 to 81.2 kg/m² with a mean of 28.8 kg/m² (SD = 6.65, median = 27.8).\nApproximately 33% of participants were classified as overweight (25 ≤ BMI &lt; 30) and 33% as obese (BMI ≥ 30), reflecting the high prevalence of excess weight in the U.S. adult population.\nThe distribution exhibited moderate right skewness (skewness = 1.2), indicating a longer tail with high BMI values\n\n\n\n\nDescriptive Statistics for BMI\n\n\nMean\nMedian\nSD\nMin\nMax\nQ1\nQ3\nIQR\nSkewness\n\n\n\n\n28.3\n27.3\n6.2\n15\n67.8\n24\n31.6\n7.6\n1.2\n\n\n\n\n\n\nDistribution of BMI Categories\n\n\nBMI Category\nPatient Count\nPercentage (%)\n\n\n\n\nUnderweight\n35\n1.7\n\n\nNormal\n652\n31.7\n\n\nOverweight\n687\n33.3\n\n\nObese\n686\n33.3\n\n\n\n\n\n\n\n\n\n\n\n\n\nNoteBMI Distribution plot and outlier detection\n\n\n\n\n\nDistribution plot of BMI (histogram + density curve)\n\n\nThe distribution of the BMI variable is right-skweed as shown in the overview. This shows that most people are around the average BMI in the data; however, some have very high BMI\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe box plot indicates that there are no outliners in the lower part ofthe distribution. The lower threshold is at approximately 13, while the upper threshold is approximately at 43.\nIn contrast the upper tail displays a substantial number of extreme values, with 43 observations identified as outliers.\n\n\n\n\n\n\n\n\n\n\n\n\nAlthough the BMI distribution shows high-value observations, these values fall within plausible physiological ranges for the NHANES population. Therefore, no outliers were removed.\n\n\n\n\n\n3.2 Summary of Exploratory Data Analysis BMI vs predictors\nAmong all variables examined, physical activity, race/ethnicity, and education level showed the strongest associations with BMI. Physically active individuals had noticeably lower BMI on average, and several race and education groups displayed meaningful mean differences. In contrast, most continuous predictors such as age, income, sleep hours, blood pressure, and alcohol use—showed very weak correlations and offered limited linear explanatory power. Please see below in the collapsed section for the full EDA.\n\n\n\n\n\n\nNotePairwise relationships with BMI\n\n\n\n\n\n\n3.3 Pairwise relationships with BMI (continuous predictors)\n\nBMI vs Age\n\n\nThe scatterplot with a LOESS smoother shows that BMI remains largely consistent across age groups. The Pearson correlation coefficient (r = 0.0144721) indicates virtually no linear association between age and BMI.\nThe corresponding coefficient of determination (\\(R^{2}\\) = 0.0002094) confirms that age explains less than 0.02% of the variance in BMI. This suggests that BMI is not influenced by age in this sample, and other demographic or lifestyle variables likely play a more substantial role in determining BMI.\n\n\n\n\n\n\n\n\n\n\n\n\n\nBMI vs log(income)\n\n\nThe scatterplot with a LOESS smoother shows a weak negative association between BMI and the logarithm of household income.\nThe Pearson correlation coefficient (r = -0.0504988) confirms that higher income is associated with slightly lower BMI values. However, this relationship is very weak (\\(R^{2}\\) = 0.00255), indicating that household income explains less than 1% of the variance in BMI.\nAlthough the direction aligns with the expected negative relationship for higher income, the effect size suggests that income has minimal influence on BMI in this sample.\n\n\n\n\n\n\n\n\n\n\n\n\n\nBMI vs Sleep\n\n\nBMI shows a negligible linear association with sleep duration (r = -0.0321021; \\(R^{2}\\) ≈ 0.001031).\nThe LOESS smoother suggests a shallow U-shape, with the lowest BMI at approximately 7.5 hours of sleep and slightly higher BMI at both shorter and longer durations.\n\n\n\n\n\n\n\n\n\n\n\n\n\nBMI vs Systolic Blood Presure\n\n\nAlthough we expected a strong positive relashionship between BMI and systolic blood pressure, the data shows only a very week positive trend. The LOESS curve suggests a small increase in BP with BMI initially, but then the relashioship plateus and even goes down slightly. This indicates that systolic blood presure alone is not a predictor in this sample.\nBMI is expected to predict high blood pressure, but the data may not show this since many patients manage their blood pressure with medication.\n\n\n\n\n\n\n\n\n\n\n\n\n\nBMI vs AlcoholDay\n\n\nThe LOESS curve is nearly flat with a slight downward tilt. The confidence interval widens as AlcoholDay increases (due to few observations with higher values) The unajusted linear correlation is appox 0.03, meaning very little to no association with BMI.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNoteAppendinx: BMI vs Alcohol Day\n\n\n\n\n\nBelow are the BMI–AlcoholDay correlations and visualizations: (i) the plot over the full 0–80 range, and (ii) the log(1 + AlcoholDay)\n\n\nShow code\ncor_alc &lt;- cor(nhanes_lm$AlcoholDay, nhanes_lm$BMI)\ncor_alc\n\n\n[1] 0.03483019\n\n\n(i) the plot over the full 0–80 range\n\n\n\n\n\n\n\n\n\n(ii) the log(1 + AlcoholDay)\n\n\n\n\n\n\n\n\n\n[1] 0.0240489\n\n\nThe correlation between alcohol and BMI is even smaller when AlcoholDay is logaritmized - 0.0240489.\n\n\n\n\n\n3.4 BMI vs Categorical predictors\n\nBMI by Gender\n\n\n \nIn this sample the average for female and male is almost the same; however, the BMI distribution is also more variable among females, as indicated by a higher standard deviation (sd = 7.04 vs. 5.43). There is no evidence that gender plays a strong role in explaining BMI differences in this sample.\n\n\n\n\n\n\n\n\n\n\n\n\n\nBMI by Physical Activity\n\n\nOn average, individuals that reported being physically active have a lower BMI (mean ≈ 27.9 kg/\\(m^{2}\\)) than those who are not (mean ≈ 29.9 kg/\\(m^{2}\\)). There is very strong evidence for a difference in BMI between physically active and inactive individuals (p &lt; 2.2 × \\(10^{-16}\\)), with an estimated mean difference of approximately 2.0 units (95% CI: [1.68, 2.36] kg/\\(m^{2}\\)). BMI is also more variable among inactive individuals (SD = 6.9 vs. 5.3), indicating a wider spread of body weight outcomes in this group.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNoteAppendix: Physical Activity Stats and T-test\n\n\n\n\n\n\n\n\nDescriptive Statistics for Physical Active\n\n\nPhysActive\nn\nMean_BMI\nSD_BMI\nMedian_BMI\n\n\n\n\nNo\n989\n29.2\n6.9\n28.0\n\n\nYes\n1071\n27.4\n5.3\n26.6\n\n\n\n\n\n\n    Welch Two Sample t-test\n\ndata:  BMI by PhysActive\nt = 6.6975, df = 1847.8, p-value = 2.805e-11\nalternative hypothesis: true difference in means between group No and group Yes is not equal to 0\n95 percent confidence interval:\n 1.285537 2.350209\nsample estimates:\n mean in group No mean in group Yes \n         29.22283          27.40496 \n\n\n\n\n\n\nBMI vs Education\n\n\nIn this sample, individuals who reported having a Colledge Graduate had a lower mean (mean ≈ 27.1 kg/\\(m^{2}\\)) compared with rest of the groups (mean ≈ 28.2 - 29.2 kg/\\(m^{2}\\)). The one-way ANOVA test provides strong evidence that the mean BMI differs across education levels (p &lt; 0.001). However the coefficient of deteermination R2 = 0.0126791 indicates that the education level only explains 1.3% in the BMI variation. This means that, while the difference is statistically significant, its practical importance is very small.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNoteAppendix: Education Stats and Anova and\n\n\n\n\n\n\n\n\nDescriptive Statistics for Education\n\n\nEducation\nn\nMean_BMI\nSD_BMI\nMedian_BMI\n\n\n\n\n8th Grade\n94\n29.2\n6.9\n27.7\n\n\n9 - 11th Grade\n299\n28.9\n7.6\n27.8\n\n\nSome College\n690\n28.7\n6.2\n27.9\n\n\nHigh School\n491\n28.2\n6.0\n27.4\n\n\nCollege Grad\n486\n27.1\n4.9\n26.5\n\n\n\n\n\nAnova\n\n\n              Df Sum Sq Mean Sq F value   Pr(&gt;F)    \nEducation      4    990   247.4   6.598 2.84e-05 ***\nResiduals   2055  77068    37.5                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nTukey\n\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = BMI ~ Education, data = nhanes_lm)\n\n$Education\n                                  diff       lwr         upr     p adj\n9 - 11th Grade-8th Grade    -0.2721042 -2.249181  1.70497290 0.9957664\nHigh School-8th Grade       -1.0267140 -2.909063  0.85563478 0.5696549\nSome College-8th Grade      -0.4749704 -2.313186  1.36324503 0.9553039\nCollege Grad-8th Grade      -2.0699378 -3.953842 -0.18603377 0.0229035\nHigh School-9 - 11th Grade  -0.7546099 -1.981100  0.47188025 0.4467253\nSome College-9 - 11th Grade -0.2028662 -1.360483  0.95475066 0.9893126\nCollege Grad-9 - 11th Grade -1.7978337 -3.026709 -0.56895799 0.0006415\nSome College-High School     0.5517436 -0.435414  1.53890127 0.5455991\nCollege Grad-High School    -1.0432238 -2.113055  0.02660738 0.0600524\nCollege Grad-Some College   -1.5949674 -2.585087 -0.60484745 0.0001120\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBMI by Race\n \nIn this sample Black and Mexican groups show higher average BMI than White, while “Other” is lower; the boxplots (red diamonds = means) reflect these shifts.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNoteAppendinx: Race Stats and Anova\n\n\n\n\n\n\n\n# A tibble: 5 × 5\n  Race1        n Mean_BMI SD_BMI Median_BMI\n  &lt;fct&gt;    &lt;int&gt;    &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt;\n1 Black      187     30.7   8.82       28.6\n2 Mexican    125     30.6   5.72       30.0\n3 Hispanic    83     28.3   4.79       27.1\n4 White     1561     27.9   5.78       27  \n5 Other      104     26.7   5.71       25.2\n\n\nCall:\n   aov(formula = BMI ~ Race1, data = nhanes_lm)\n\nTerms:\n                   Race1 Residuals\nSum of Squares   2263.28  75794.92\nDeg. of Freedom        4      2055\n\nResidual standard error: 6.073152\nEstimated effects may be unbalanced\n\n\nOne-way ANOVA indicates a significant overall difference across Race1 (p &lt; 0.001); pairwise Tukey comparisons can then identify which specific pairs differ.\n\n\n\n\n\n\nBMI vs Smoke\nSmokers show an approximate 1.1 kg/\\(m^{2}\\) lower mean BMI than non-smokers. The T-test result tells us that there is very strong evidence that the median BMI between non-smokers and smokers is not zero.(appendix)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNoteAppendix: BMI~Smoke t-test\n\n\n\n\n\n\n\nShow code\nt_test_Smoke &lt;- t.test(BMI ~ SmokeNow, data = nhanes_lm)\nt_test_Smoke\n\n\n\n    Welch Two Sample t-test\n\ndata:  BMI by SmokeNow\nt = 4.1853, df = 1947.8, p-value = 2.974e-05\nalternative hypothesis: true difference in means between group No and group Yes is not equal to 0\n95 percent confidence interval:\n 0.6065475 1.6762202\nsample estimates:\n mean in group No mean in group Yes \n         28.79577          27.65439",
    "crumbs": [
      "Home",
      "ML Portfolio",
      "NHANES - R Project",
      "Linear Regression Analysis - Predicting Body Mass Index"
    ]
  },
  {
    "objectID": "ml-portfolio/02_nhanes_R/01_linear_model.html#linear-model",
    "href": "ml-portfolio/02_nhanes_R/01_linear_model.html#linear-model",
    "title": "Linear Regression Analysis - Predicting Body Mass Index",
    "section": "4 Linear Model",
    "text": "4 Linear Model\nSummary of Linear Modeling Progression (Collapsed Below)\nTo reach the final interaction model, we estimated a sequence of nested linear models. The simple BMI ~ Age regression showed no meaningful association, and adding basic demographics improved the fit only slightly, with race contributing the most. Socioeconomic factors provided minimal additional explanatory power. Lifestyle and clinical variables strengthened the model somewhat, with physical activity, smoking status, systolic blood pressure, and race emerging as the most consistent predictors of BMI. All earlier models and their outputs are collapsed below, while the final interaction model remains visible for interpretation.\n\n\n\n\n\n\nNoteLinear Modeling Progression\n\n\n\n\n\n\n4.1 BMI ~ Age\nWe are starting with a simpler linear model\n\n\nThe intercept is 28.01 kg/\\(m^{2}\\). The interpretation has no meaning as it represents the BMI at age 0 for an adult. (part of the linear fit)\nThe slope is 0.005 kg/\\(m^{2}\\) and the interpretation would be that for the each year increase the BMI will increase with 0.005. The p value is 0.512 and we can say that in this linear model there is no evidence of a linear assocciation between BMI and Age.\nWith a fit \\(R^{2}\\) = 0.0002 (adj. \\(R^{2}\\) = -0.0002) Age explaines none of the variability in BMI\n\n\n\nShow code\nm_age &lt;-lm(BMI ~ Age, data = nhanes_lm)\n\n\n\n\nShow code\n#summary(m_age)\n\n\nage_sum &lt;- tidy(m_age, conf.int = TRUE)\n#age_sum\nage_fit &lt;- glance(m_age)[, c(\"r.squared\",\"adj.r.squared\",\"sigma\",\"nobs\")]\n\n\n\nkable(age_sum, digits=3, caption=\"BMI ~ Age: coefficient table (with 95% CI)\")\n\n\n\nBMI ~ Age: coefficient table (with 95% CI)\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\nconf.low\nconf.high\n\n\n\n\n(Intercept)\n28.018\n0.418\n67.033\n0.000\n27.198\n28.838\n\n\nAge\n0.005\n0.008\n0.657\n0.512\n-0.011\n0.022\n\n\n\n\n\nShow code\n#kable(age_fit, digits=3, caption=\"BMI ~ Age: model fit\")\nage_fit\n\n\n# A tibble: 1 × 4\n  r.squared adj.r.squared sigma  nobs\n      &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;\n1  0.000209     -0.000276  6.16  2060\n\n\n\n\n\n\n4.2 Model 1: Demographic\nWe will add core demographic variables to the model: Age + Gender + Race\nModel: BMI ~ Age + Gender + Race\n\nWe fit a multiple linear model with BMI as the response and Age (continuous), Gender (female = reference), and Race (White = reference) as covariates.\n\n\n\nShow code\nM1 &lt;- lm(BMI ~ Age + Gender + Race1, data = nhanes_lm)\n\nsummary(M1)\n\n\n\nCall:\nlm(formula = BMI ~ Age + Gender + Race1, data = nhanes_lm)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-15.210  -4.209  -0.949   3.436  40.186 \n\nCoefficients:\n               Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   27.117470   0.463686  58.482  &lt; 2e-16 ***\nAge            0.013510   0.008406   1.607   0.1082    \nGendermale     0.221968   0.272635   0.814   0.4156    \nRace1Black     2.872157   0.472655   6.077 1.46e-09 ***\nRace1Mexican   2.802671   0.571678   4.903 1.02e-06 ***\nRace1Other    -1.131178   0.619031  -1.827   0.0678 .  \nRace1Hispanic  0.446401   0.688336   0.649   0.5167    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.071 on 2053 degrees of freedom\nMultiple R-squared:  0.03055,   Adjusted R-squared:  0.02772 \nF-statistic: 10.78 on 6 and 2053 DF,  p-value: 7.701e-12\n\n\nShow code\n# Coefficients with 95% CIs (t-tests)\n# core_coef &lt;- broom::tidy(M1, conf.int = TRUE)\n# core_coef\n\n# M1_sum &lt;- tidy(M1, conf.int = TRUE)\n# kable(M1_sum, digits=3, caption=\"BMI ~ Age + Gender + Race coefficient table (with 95% CI)\")\n\n\n\n# Model fit\n# M1_fit  &lt;- broom::glance(M1)[, c(\"r.squared\",\"adj.r.squared\",\"sigma\",\"df\",\"nobs\")]\n# knitr::kable(M1_fit,  digits = 3, caption = \"Core model: fit statistics\")\n\n\nIn this model the Race differences between groups relative to White: Black (+ 2.87 kg/\\(m^{2}\\), p &lt; \\(10^{-8}\\)) and Mexican (+2.80 kg/\\(m^{2}\\), p &lt; \\(10^{-6}\\)) participants have a higher BMI on average, while Other shows very weak evidence that the BMI is lower on everage than White (-1.13 kg/\\(m^{2}\\), p &lt; 0.068) and for Hispanix group there is no evidence that the BMI is different from White category on average (+0.45 kg/\\(m^{2}\\), p &lt; 0.517). The adjusted \\(R^{2}\\) = 0.028, meaning that demographics only explain ~2.8% of BMI variability\nF-tests for M1 (BMI ~ Age + Gender + Race1)\n\n\nShow code\nM1_drop1 &lt;- drop1(M1, test = \"F\")\nM1_drop1 \n\n\nSingle term deletions\n\nModel:\nBMI ~ Age + Gender + Race1\n       Df Sum of Sq   RSS    AIC F value    Pr(&gt;F)    \n&lt;none&gt;              75673 7437.7                      \nAge     1     95.20 75768 7438.3  2.5827    0.1082    \nGender  1     24.43 75698 7436.3  0.6629    0.4156    \nRace1   4   2318.52 77992 7491.8 15.7252 1.109e-12 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nUsing drop1() we test each term conditional on the others. Race is associated with BMI; Age and Gender are not, at this stage.\n\n\n4.3 Adding Socioeconomic factors\nWe are adding socioeconomic factors to our model\n\n\nShow code\nM2 &lt;- update(M1, . ~ . + Education + log_income)\nsummary(M2)\n\n\n\nCall:\nlm(formula = BMI ~ Age + Gender + Race1 + Education + log_income, \n    data = nhanes_lm)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-14.858  -4.169  -0.913   3.454  39.780 \n\nCoefficients:\n                         Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)             28.034963   2.066514  13.566  &lt; 2e-16 ***\nAge                      0.015941   0.008473   1.881   0.0601 .  \nGendermale               0.191993   0.272588   0.704   0.4813    \nRace1Black               2.671400   0.481595   5.547 3.28e-08 ***\nRace1Mexican             2.649685   0.593333   4.466 8.41e-06 ***\nRace1Other              -1.077031   0.623601  -1.727   0.0843 .  \nRace1Hispanic            0.344172   0.692346   0.497   0.6192    \nEducation9 - 11th Grade -0.030781   0.733418  -0.042   0.9665    \nEducationHigh School    -0.621045   0.703421  -0.883   0.3774    \nEducationSome College    0.164729   0.698290   0.236   0.8135    \nEducationCollege Grad   -1.224686   0.723380  -1.693   0.0906 .  \nlog_income              -0.055827   0.185911  -0.300   0.7640    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.053 on 2048 degrees of freedom\nMultiple R-squared:  0.03873,   Adjusted R-squared:  0.03357 \nF-statistic: 7.501 on 11 and 2048 DF,  p-value: 9.159e-13\n\n\nAfteradding the Education and log_income as covariates the BMI remains higher forBlack and Mexican participants vs White. Age and particpats that are Colledge Graduates shows a very weak association with BMI. The adj. \\(R^{2}\\) shows an explanability of 3.4%\nTerm-wise F-tests\n\n\nShow code\nM2_drop1 &lt;- drop1(M2, test = \"F\")\nM2_drop1\n\n\nSingle term deletions\n\nModel:\nBMI ~ Age + Gender + Race1 + Education + log_income\n           Df Sum of Sq   RSS    AIC F value    Pr(&gt;F)    \n&lt;none&gt;                  75035 7430.2                      \nAge         1    129.68 75165 7431.8  3.5393  0.060071 .  \nGender      1     18.18 75053 7428.7  0.4961  0.481305    \nRace1       4   1912.91 76948 7474.1 13.0527 1.687e-10 ***\nEducation   4    599.27 75634 7438.6  4.0891  0.002643 ** \nlog_income  1      3.30 75038 7428.3  0.0902  0.763989    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nTerm-wise F-tests: BMI differs overall by Race and Education; Age is borderline; Gender and log(Income) show little added association (conditional on other covariates).\n\n\n4.4 Adding Lifestyle & Clinical predictors\n\n\nShow code\nM3 &lt;- update(M2, . ~ . + PhysActive + SleepHrsNight + AlcoholDay + SmokeNow + BPSysAve)\nsummary(M3)\n\n\n\nCall:\nlm(formula = BMI ~ Age + Gender + Race1 + Education + log_income + \n    PhysActive + SleepHrsNight + AlcoholDay + SmokeNow + BPSysAve, \n    data = nhanes_lm)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-15.915  -3.999  -0.831   3.537  37.748 \n\nCoefficients:\n                         Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)             29.573516   2.335666  12.662  &lt; 2e-16 ***\nAge                     -0.015609   0.009670  -1.614 0.106648    \nGendermale               0.014294   0.274346   0.052 0.958454    \nRace1Black               3.006900   0.476562   6.310 3.42e-10 ***\nRace1Mexican             2.241999   0.584376   3.837 0.000129 ***\nRace1Other              -0.531417   0.616321  -0.862 0.388656    \nRace1Hispanic            0.416809   0.679956   0.613 0.539948    \nEducation9 - 11th Grade  0.089781   0.720029   0.125 0.900781    \nEducationHigh School    -0.516741   0.690459  -0.748 0.454304    \nEducationSome College    0.253163   0.685239   0.369 0.711830    \nEducationCollege Grad   -0.926147   0.719078  -1.288 0.197904    \nlog_income              -0.110284   0.183536  -0.601 0.547982    \nPhysActiveYes           -1.809196   0.278270  -6.502 9.96e-11 ***\nSleepHrsNight           -0.082643   0.098545  -0.839 0.401770    \nAlcoholDay               0.074228   0.041594   1.785 0.074476 .  \nSmokeNowYes             -2.181678   0.299600  -7.282 4.67e-13 ***\nBPSysAve                 0.022322   0.008524   2.619 0.008893 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.928 on 2043 degrees of freedom\nMultiple R-squared:  0.08013,   Adjusted R-squared:  0.07293 \nF-statistic: 11.12 on 16 and 2043 DF,  p-value: &lt; 2.2e-16\n\n\nAfter adding lifestyle and clinical predictors to our Model BMI we can observe that BMI stays higher for Black and Mexican in comparision with White participants. Physically Active participants have a lower BMI, and Smoking participants have a lower BMI. Effects are conditional on the others (treatment coding); results are associations, not causal.\nTerm-wise F-tests\n\n\nShow code\nM3_drop1 &lt;- drop1(M3, test = \"F\")\nM3_drop1\n\n\nSingle term deletions\n\nModel:\nBMI ~ Age + Gender + Race1 + Education + log_income + PhysActive + \n    SleepHrsNight + AlcoholDay + SmokeNow + BPSysAve\n              Df Sum of Sq   RSS    AIC F value    Pr(&gt;F)    \n&lt;none&gt;                     71803 7349.5                      \nAge            1     91.57 71895 7350.2  2.6055  0.106648    \nGender         1      0.10 71804 7347.5  0.0027  0.958454    \nRace1          4   1852.00 73655 7394.0 13.1736 1.346e-10 ***\nEducation      4    430.36 72234 7353.8  3.0612  0.015826 *  \nlog_income     1     12.69 71816 7347.9  0.3611  0.547982    \nPhysActive     1   1485.64 73289 7389.7 42.2705 9.962e-11 ***\nSleepHrsNight  1     24.72 71828 7348.2  0.7033  0.401770    \nAlcoholDay     1    111.93 71915 7350.7  3.1848  0.074476 .  \nSmokeNow       1   1863.69 73667 7400.3 53.0269 4.673e-13 ***\nBPSysAve       1    241.01 72044 7354.4  6.8573  0.008893 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nTerm-wise F-tests for M3 (BMI ~ Age + Gender + Race1 + Education + log_income + PhysActive + SleepHrsNight + AlcoholDay + SmokeNow + BPSysAve)\n\n\n\n\n\n4.5 Adding Interactions\nWe extended the model with prespecified interactions to test whether the association between:\n\nPhysActive × Gender - Based on Gender Differences in Exercise Habits and Quality of Life Reports1, physical activity patterns differ significantly by gender. Here we test whether the BMI–activity association varies by sex.\nPhysActive × Education - According to the research Education leads to a more physically active lifestyle2, “one additional year of education leads to a 0.62-unit higher overall physical activity”. We are testing if in our sample the activity–BMI association varies across socioeconomic factors (education levels).\nGender × SmokeNow - Based on the report from Swiss association for tabacco control3, there are known gender differences in smoking paterns. In out sample we are testing whether the smoking-BMI association differs by sex.\n\n\nM4 &lt;- update(M3, . ~ . + PhysActive:Gender + PhysActive:Education + Gender:SmokeNow)\n\n\n\n\n\n\n\nNoteModel Summary- result\n\n\n\n\n\n\n\nShow code\nsummary(M4)\n\n\n\nCall:\nlm(formula = BMI ~ Age + Gender + Race1 + Education + log_income + \n    PhysActive + SleepHrsNight + AlcoholDay + SmokeNow + BPSysAve + \n    Gender:PhysActive + Education:PhysActive + Gender:SmokeNow, \n    data = nhanes_lm)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-15.168  -4.057  -0.895   3.396  37.770 \n\nCoefficients:\n                                       Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                           27.726849   2.380324  11.648  &lt; 2e-16 ***\nAge                                   -0.014841   0.009598  -1.546  0.12221    \nGendermale                             0.611595   0.482437   1.268  0.20504    \nRace1Black                             2.890277   0.473409   6.105 1.23e-09 ***\nRace1Mexican                           2.292266   0.580298   3.950 8.08e-05 ***\nRace1Other                            -0.520097   0.611616  -0.850  0.39522    \nRace1Hispanic                          0.585686   0.679784   0.862  0.38902    \nEducation9 - 11th Grade                1.154768   0.876821   1.317  0.18799    \nEducationHigh School                  -0.145821   0.849861  -0.172  0.86378    \nEducationSome College                  0.855728   0.839405   1.019  0.30811    \nEducationCollege Grad                  0.269230   0.937998   0.287  0.77412    \nlog_income                            -0.065774   0.183019  -0.359  0.71935    \nPhysActiveYes                         -0.262527   1.337241  -0.196  0.84438    \nSleepHrsNight                         -0.099740   0.098131  -1.016  0.30956    \nAlcoholDay                             0.084933   0.041469   2.048  0.04068 *  \nSmokeNowYes                           -0.661655   0.433203  -1.527  0.12683    \nBPSysAve                               0.025625   0.008505   3.013  0.00262 ** \nGendermale:PhysActiveYes               1.084032   0.538843   2.012  0.04437 *  \nEducation9 - 11th Grade:PhysActiveYes -3.183134   1.482250  -2.148  0.03187 *  \nEducationHigh School:PhysActiveYes    -1.531381   1.409680  -1.086  0.27746    \nEducationSome College:PhysActiveYes   -2.013071   1.376690  -1.462  0.14383    \nEducationCollege Grad:PhysActiveYes   -2.849886   1.435170  -1.986  0.04720 *  \nGendermale:SmokeNowYes                -2.650774   0.538496  -4.923 9.23e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.879 on 2037 degrees of freedom\nMultiple R-squared:  0.09791,   Adjusted R-squared:  0.08817 \nF-statistic: 10.05 on 22 and 2037 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n\nInteraction observation:\n\nGender:SmokingNow: there is very strong evidence that smoking is linked to a lower BMI for both sexes: women ~ 0.7 kg/\\(m^{2}\\) lower and men ~ 3.3 kg/\\(m^{2}\\) compared with non-smokers.\nPhysActivity:Gender: there is evidence that difference in average BMIassociated with physical acivity in not 0 men. In the baseline group women show a small decrease with activity (~ 0.3kg/\\(m^{2}\\)). Men add approx 1.1 kg/\\(m^{2}\\) to the female difference.\nPhysActivity:Education: in lower (9–11) and higher (College) education groups, being active is associated with a noticeably lower BMI than in the 8th-grade group.\n\n\nAll of these interaction are conditional associations (not causal)\n\nAs we added the interaction we oberve that AlcoholDay shows a small positive association with BMI (for each additional drink a day the BMI increases with 0.085 kg/\\(m^{2}\\), p = 0.04), conditional on other covariates.\nTerm-wise F-tests\n\nM4_drop1 &lt;- drop1(M4, test = \"F\")\n\n\n\n\n\n\n\nNoteF-test result\n\n\n\n\n\n\n\nShow code\nM4_drop1\n\n\nSingle term deletions\n\nModel:\nBMI ~ Age + Gender + Race1 + Education + log_income + PhysActive + \n    SleepHrsNight + AlcoholDay + SmokeNow + BPSysAve + Gender:PhysActive + \n    Education:PhysActive + Gender:SmokeNow\n                     Df Sum of Sq   RSS    AIC F value    Pr(&gt;F)    \n&lt;none&gt;                            70416 7321.3                      \nAge                   1     82.64 70498 7321.7  2.3907   0.12221    \nRace1                 4   1759.80 72175 7364.2 12.7270 3.116e-10 ***\nlog_income            1      4.46 70420 7319.5  0.1292   0.71935    \nSleepHrsNight         1     35.71 70451 7320.4  1.0330   0.30956    \nAlcoholDay            1    145.00 70561 7323.6  4.1947   0.04068 *  \nBPSysAve              1    313.77 70729 7328.5  9.0769   0.00262 ** \nGender:PhysActive     1    139.91 70556 7323.4  4.0473   0.04437 *  \nEducation:PhysActive  4    263.23 70679 7321.0  1.9037   0.10719    \nGender:SmokeNow       1    837.64 71253 7343.7 24.2315 9.229e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\nTerm-wise F-tests summary: BMI is associated with race, systolic BP, and shows effect modification for Gender:Smoking and Gender:Physical activity. Education:Physical activity is not supported",
    "crumbs": [
      "Home",
      "ML Portfolio",
      "NHANES - R Project",
      "Linear Regression Analysis - Predicting Body Mass Index"
    ]
  },
  {
    "objectID": "ml-portfolio/02_nhanes_R/01_linear_model.html#research-questions",
    "href": "ml-portfolio/02_nhanes_R/01_linear_model.html#research-questions",
    "title": "Linear Regression Analysis - Predicting Body Mass Index",
    "section": "5 Research Questions",
    "text": "5 Research Questions\nAfter adjusting for covariates, how does BMI vary with Age?\nAdjusted for all covariates, the term-wise F-test (drop1) shows little evidence of a linear association between age and BMI (p ≈ 0.12)\nDo demographic factors show overall association with BMI?\n\nRace/ethnicity: Yes. Strong overall association (clear F-test).\nEducation: Yes (overall main effect), but no activity–education interaction.\nGender: No large main effect, but gender modifies the associations of physical activity and smoking with BMI.\n\nAre lifestile factors (PsyActive, AlcoholDay, SleepNight, SmokeNow) associated with BMI, and how much?\n\nAt the reference education (8th Grade), females show a small reduction with activity (PhysActive main term).\nMales add the Gender:PhysActive interaction, show an increase with activity.\nIn 9–11th Grade and College Grad, the Education:PhysActive interactions are negative, showing that there is an associated reduction than in the reference education. However with the Drop1 test there is weak to no evidence that there is an interaction bewteen Education and PhyActive\n\nHow much variance is explained by the model?\nThe model’s adjusted \\(R^{2}\\) ≈ 0.088, so the model explains only 8.8% of the variability in BMI.",
    "crumbs": [
      "Home",
      "ML Portfolio",
      "NHANES - R Project",
      "Linear Regression Analysis - Predicting Body Mass Index"
    ]
  },
  {
    "objectID": "ml-portfolio/02_nhanes_R/01_linear_model.html#footnotes",
    "href": "ml-portfolio/02_nhanes_R/01_linear_model.html#footnotes",
    "title": "Linear Regression Analysis - Predicting Body Mass Index",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nSee PMC article.↩︎\nSee PMC article.↩︎\nSee AT report.↩︎",
    "crumbs": [
      "Home",
      "ML Portfolio",
      "NHANES - R Project",
      "Linear Regression Analysis - Predicting Body Mass Index"
    ]
  },
  {
    "objectID": "ml-portfolio/01_labs_R/04_svm/svm_lab_iris.html",
    "href": "ml-portfolio/01_labs_R/04_svm/svm_lab_iris.html",
    "title": "Support Vector Machine (Lab)",
    "section": "",
    "text": "#\nlibrary(tidyverse)\nlibrary(e1071) # package for SVM\nlibrary(caret) # helper functions",
    "crumbs": [
      "Home",
      "ML Portfolio",
      "R Labs",
      "Support Vector Machine (Lab)"
    ]
  },
  {
    "objectID": "ml-portfolio/01_labs_R/04_svm/svm_lab_iris.html#loading-packages",
    "href": "ml-portfolio/01_labs_R/04_svm/svm_lab_iris.html#loading-packages",
    "title": "Support Vector Machine (Lab)",
    "section": "",
    "text": "#\nlibrary(tidyverse)\nlibrary(e1071) # package for SVM\nlibrary(caret) # helper functions",
    "crumbs": [
      "Home",
      "ML Portfolio",
      "R Labs",
      "Support Vector Machine (Lab)"
    ]
  },
  {
    "objectID": "ml-portfolio/01_labs_R/04_svm/svm_lab_iris.html#loading-the-data",
    "href": "ml-portfolio/01_labs_R/04_svm/svm_lab_iris.html#loading-the-data",
    "title": "Support Vector Machine (Lab)",
    "section": "2 Loading the data",
    "text": "2 Loading the data\nInspect the structure of the data\n\ndata(iris)\nstr(iris)\n\n'data.frame':   150 obs. of  5 variables:\n $ Sepal.Length: num  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...\n $ Sepal.Width : num  3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...\n $ Petal.Length: num  1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...\n $ Petal.Width : num  0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...\n $ Species     : Factor w/ 3 levels \"setosa\",\"versicolor\",..: 1 1 1 1 1 1 1 1 1 1 ...",
    "crumbs": [
      "Home",
      "ML Portfolio",
      "R Labs",
      "Support Vector Machine (Lab)"
    ]
  },
  {
    "objectID": "ml-portfolio/01_labs_R/04_svm/svm_lab_iris.html#view-the-data",
    "href": "ml-portfolio/01_labs_R/04_svm/svm_lab_iris.html#view-the-data",
    "title": "Support Vector Machine (Lab)",
    "section": "3 View the data",
    "text": "3 View the data\nPlot the data by Sepal\n\niris |&gt; \n    ggplot(aes(x = Sepal.Length, y = Sepal.Width, color = Species))+\n    geom_point()\n\n\n\n\n\n\n\n\nPlot the data by petal\n\niris |&gt; \n    ggplot(aes(x = Petal.Length, y = Petal.Width, color = Species))+\n    geom_point()",
    "crumbs": [
      "Home",
      "ML Portfolio",
      "R Labs",
      "Support Vector Machine (Lab)"
    ]
  },
  {
    "objectID": "ml-portfolio/01_labs_R/04_svm/svm_lab_iris.html#prepare-for-trainig",
    "href": "ml-portfolio/01_labs_R/04_svm/svm_lab_iris.html#prepare-for-trainig",
    "title": "Support Vector Machine (Lab)",
    "section": "4 Prepare for Trainig",
    "text": "4 Prepare for Trainig\nThis function creates a stratified split of data. It splits the dataset into training and testing p = 85 (85% training) while preserving the class proportion of the Species variable. In other words this makes sure the proportion of each class (setosa, versicolor, virginica) in the split is the same as in the original dataset. List = FALSE - when you want the vector as a row numbers not as a list\n\nset.seed(42)\nindices &lt;- createDataPartition(iris$Species, p = .85, list = FALSE)\n\nThen I use it like this:\n\ntrain = 85% rows\ntest_in = 15% (remainig) -indices\ntest_truth = actual labels for evaluating predictions\n\n\ntrain &lt;- iris %&gt;% slice(indices)\ntest_in &lt;- iris %&gt;% slice(-indices) %&gt;% select(-Species)\ntest_truth &lt;- iris %&gt;% slice(-indices) %&gt;% pull(Species)",
    "crumbs": [
      "Home",
      "ML Portfolio",
      "R Labs",
      "Support Vector Machine (Lab)"
    ]
  },
  {
    "objectID": "ml-portfolio/01_labs_R/04_svm/svm_lab_iris.html#train-the-svm---linear-kernel",
    "href": "ml-portfolio/01_labs_R/04_svm/svm_lab_iris.html#train-the-svm---linear-kernel",
    "title": "Support Vector Machine (Lab)",
    "section": "5 Train the SVM - Linear kernel",
    "text": "5 Train the SVM - Linear kernel\nThe SVM function has the default cost of 10\n\nset.seed(42)\niris_svm &lt;- svm(Species ~ ., train, kernel = \"linear\", scale = TRUE, cost = 10)\nsummary(iris_svm)\n\n\nCall:\nsvm(formula = Species ~ ., data = train, kernel = \"linear\", cost = 10, \n    scale = TRUE)\n\n\nParameters:\n   SVM-Type:  C-classification \n SVM-Kernel:  linear \n       cost:  10 \n\nNumber of Support Vectors:  17\n\n ( 2 8 7 )\n\n\nNumber of Classes:  3 \n\nLevels: \n setosa versicolor virginica\n\n\nwe can visualize the SVM decision boundaries only in two dimensions, even though the model was trained in four dimensions (all iris features).\n\nplot(iris_svm, train, Petal.Length ~ Petal.Width)\n\n\n\n\n\n\n\n\nFor Sepal leaf Dimensions it is needed to be sliced the other dimenstions at a reasonable point\n\nplot(iris_svm, train, Sepal.Length ~ Sepal.Width,\n     slice = list(Petal.Length = 4.5, Petal.Width = 1.75))\n\n\n\n\n\n\n\n\nThe plots does not show the full SVM, only one projection at the time of the decision Surface into two dimensions\n\n5.1 Predictions\n\ntest_pred &lt;- predict(iris_svm, test_in)\ntable(test_pred)\n\ntest_pred\n    setosa versicolor  virginica \n         7          7          7 \n\n\n\n\n5.2 Results\n\nconf_matrix &lt;- confusionMatrix(test_pred, test_truth)\nconf_matrix\n\nConfusion Matrix and Statistics\n\n            Reference\nPrediction   setosa versicolor virginica\n  setosa          7          0         0\n  versicolor      0          7         0\n  virginica       0          0         7\n\nOverall Statistics\n                                     \n               Accuracy : 1          \n                 95% CI : (0.8389, 1)\n    No Information Rate : 0.3333     \n    P-Value [Acc &gt; NIR] : 9.56e-11   \n                                     \n                  Kappa : 1          \n                                     \n Mcnemar's Test P-Value : NA         \n\nStatistics by Class:\n\n                     Class: setosa Class: versicolor Class: virginica\nSensitivity                 1.0000            1.0000           1.0000\nSpecificity                 1.0000            1.0000           1.0000\nPos Pred Value              1.0000            1.0000           1.0000\nNeg Pred Value              1.0000            1.0000           1.0000\nPrevalence                  0.3333            0.3333           0.3333\nDetection Rate              0.3333            0.3333           0.3333\nDetection Prevalence        0.3333            0.3333           0.3333\nBalanced Accuracy           1.0000            1.0000           1.0000\n\n\nThe result is 100% accuracy\n\n\n5.3 Overfitting?\nDid the model overfit? even though we got 100% accuracy that might not mean overfitting because:\n\nsetosa is completely linearly separable.\nversicolor vs. virginica are also almost linearly separable in petal space.",
    "crumbs": [
      "Home",
      "ML Portfolio",
      "R Labs",
      "Support Vector Machine (Lab)"
    ]
  },
  {
    "objectID": "ml-portfolio/01_labs_R/04_svm/svm_lab_iris.html#train-the-dataset-on-radial-kernel",
    "href": "ml-portfolio/01_labs_R/04_svm/svm_lab_iris.html#train-the-dataset-on-radial-kernel",
    "title": "Support Vector Machine (Lab)",
    "section": "6 Train the dataset on radial kernel",
    "text": "6 Train the dataset on radial kernel\n\nRadial kernel - allows complex curved boundaries\nHigh cost - tries to classify training points almost perfectly (risk of overfitting)\n\n\nset.seed(42)\n\niris_svm2 &lt;- svm(Species ~ ., train, kernel = \"radial\", scale = TRUE, cost = 100)\nsummary(iris_svm2)\n\n\nCall:\nsvm(formula = Species ~ ., data = train, kernel = \"radial\", cost = 100, \n    scale = TRUE)\n\n\nParameters:\n   SVM-Type:  C-classification \n SVM-Kernel:  radial \n       cost:  100 \n\nNumber of Support Vectors:  29\n\n ( 6 11 12 )\n\n\nNumber of Classes:  3 \n\nLevels: \n setosa versicolor virginica\n\n\n\n6.1 Plots\n\nplot(iris_svm2, train, Petal.Length ~ Petal.Width, slice = list(Sepal.Length = 6, Sepal.Width = 3))\n\n\n\n\n\n\n\n\n\n plot(iris_svm2, train, Sepal.Length ~ Sepal.Width, slice = list(Petal.Length = 4.5, Petal.Width = 1.75))\n\n\n\n\n\n\n\n\n\n\n6.2 Predictions\n\ntest_pred2 &lt;- predict(iris_svm2, test_in)\ntable(test_pred2)\n\ntest_pred2\n    setosa versicolor  virginica \n         7          8          6 \n\n\n\n\n6.3 Results\n\nconf_matrix2 &lt;- confusionMatrix(test_pred2, test_truth)\nconf_matrix2\n\nConfusion Matrix and Statistics\n\n            Reference\nPrediction   setosa versicolor virginica\n  setosa          7          0         0\n  versicolor      0          7         1\n  virginica       0          0         6\n\nOverall Statistics\n                                          \n               Accuracy : 0.9524          \n                 95% CI : (0.7618, 0.9988)\n    No Information Rate : 0.3333          \n    P-Value [Acc &gt; NIR] : 4.111e-09       \n                                          \n                  Kappa : 0.9286          \n                                          \n Mcnemar's Test P-Value : NA              \n\nStatistics by Class:\n\n                     Class: setosa Class: versicolor Class: virginica\nSensitivity                 1.0000            1.0000           0.8571\nSpecificity                 1.0000            0.9286           1.0000\nPos Pred Value              1.0000            0.8750           1.0000\nNeg Pred Value              1.0000            1.0000           0.9333\nPrevalence                  0.3333            0.3333           0.3333\nDetection Rate              0.3333            0.3333           0.2857\nDetection Prevalence        0.3333            0.3810           0.2857\nBalanced Accuracy           1.0000            0.9643           0.9286\n\n\nSetosa (perfect): Prediction = Truth in all 7 cases → flawless.\nVersicolor (1 mistake): One virginica was misclassified as versicolor.\nVirginica (1 mistake): The same misclassification reflects here → 6/7 correct.\nCost (C) controls how strictly the SVM tries to separate the classes.\n\n\n6.4 High cost (C = large)\nMeans:\n\nMisclassification is heavily punished\nSVM tries very hard to separate data perfectly\nMargin becomes narrow\nOnly the critical points (right on the boundary) stay as support vectors\nFewer points are allowed inside the margin Results in fewer support vectors Because the model becomes more rigid and pushes as many points as possible away from the margin.\n\n\n\n6.5 Low cost (C small)\nMeans:\n\nMisclassification is acceptable\nSVM allows violations\nMargin becomes wide\nMore points fall inside or on the margin\nMore points become support vectors\n\nResult in more support vectors Because the model becomes more tolerant, allowing many points to influence the boundary.",
    "crumbs": [
      "Home",
      "ML Portfolio",
      "R Labs",
      "Support Vector Machine (Lab)"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome",
    "section": "",
    "text": "Alin Sever – Data Analyst & MSc in Applied Data Science\nWelcome to my professional portfolio.\nThis website showcases selected analytical, machine learning, and data science projects developed during my MSc at the Lucerne University of Applied Sciences and through independent work.\nThe portfolio is divided into two main sections:\n\nML Portfolio — machine learning work in R and Python\n\nStandalone Projects — applied analysis, dashboards, data pipelines, and research projects\n\nUse the sidebar to navigate through the content."
  },
  {
    "objectID": "ml-portfolio/01_labs_R/index.html",
    "href": "ml-portfolio/01_labs_R/index.html",
    "title": "R Machine Learning Labs",
    "section": "",
    "text": "This folder will include R-based ML labs such as SVM, logistic regression, clustering, and other course exercises.\nMore content will be added soon.",
    "crumbs": [
      "Home",
      "ML Portfolio",
      "R Labs"
    ]
  },
  {
    "objectID": "ml-portfolio/02_nhanes_R/02_support_vector_machine.html",
    "href": "ml-portfolio/02_nhanes_R/02_support_vector_machine.html",
    "title": "Predicting Obesity using Support Vector Machines",
    "section": "",
    "text": "In the previous chapter, we examined how demographic, socioeconomic, lifestyle, and clinical factors were linearly associated with BMI. While this offered insight into individual predictors, it also showed that BMI relationships are weak, complex, and often non-linear. Building on that foundation, the next step is to evaluate whether obesity can be predicted more effectively using machine learning methods that capture non-linear patterns.\nThe goal of this chapter is to develop and assess Support Vector Machine (SVM) models for classifying individuals as obese (BMI ≥ 30 kg/m²) or not obese using the same cleaned NHANES dataset. Predictors include demographics, socioeconomic indicators, lifestyle behaviors, and clinical variables. Two SVM variants are considered: a linear SVM with a simple, interpretable boundary and a radial SVM (RBF) that can model non-linear relationships. Model performance is evaluated using repeated cross-validation and then tested on an independent test set.\nTogether, these models allow us to explore whether moving from classical regression to non-linear machine learning improves predictive accuracy, and to compare the trade-offs between interpretability and flexibility when modelling obesity risk.",
    "crumbs": [
      "Home",
      "ML Portfolio",
      "NHANES - R Project",
      "Predicting Obesity using Support Vector Machines"
    ]
  },
  {
    "objectID": "ml-portfolio/02_nhanes_R/02_support_vector_machine.html#outcome-variable",
    "href": "ml-portfolio/02_nhanes_R/02_support_vector_machine.html#outcome-variable",
    "title": "Predicting Obesity using Support Vector Machines",
    "section": "3.1 Outcome Variable",
    "text": "3.1 Outcome Variable\nThe prediction task is framed as a binary classification problem. Body Mass Index (BMI) was converted into a categorical variable:\n\n“obese” for BMI ≥ 30 kg/m²\n“not_obese” otherwise\n\nThis aligns with standard clinical definitions and enables direct classification using SVM algorithms.",
    "crumbs": [
      "Home",
      "ML Portfolio",
      "NHANES - R Project",
      "Predicting Obesity using Support Vector Machines"
    ]
  },
  {
    "objectID": "ml-portfolio/02_nhanes_R/02_support_vector_machine.html#predictor-variables",
    "href": "ml-portfolio/02_nhanes_R/02_support_vector_machine.html#predictor-variables",
    "title": "Predicting Obesity using Support Vector Machines",
    "section": "3.2 Predictor Variables",
    "text": "3.2 Predictor Variables\nThe predictors used in this analysis are the same cleaned variables from the linear regression project:\n\nDemographic: Age, Gender, Race/Ethnicity, Education\nSocioeconomic: Log-transformed household income\nLifestyle: Physical activity, smoking status, sleep hours, alcohol consumption\nClinical: Average systolic blood pressure\n\nAll predictors were selected based on theoretical relevance and completeness in the cleaned dataset.",
    "crumbs": [
      "Home",
      "ML Portfolio",
      "NHANES - R Project",
      "Predicting Obesity using Support Vector Machines"
    ]
  },
  {
    "objectID": "ml-portfolio/02_nhanes_R/02_support_vector_machine.html#data-partitioning",
    "href": "ml-portfolio/02_nhanes_R/02_support_vector_machine.html#data-partitioning",
    "title": "Predicting Obesity using Support Vector Machines",
    "section": "3.3 Data Partitioning",
    "text": "3.3 Data Partitioning\nTo fairly assess model performance, the dataset was split into:\n\nTraining set: 80% of the data\nTesting set: 20% of the data\n\nThe split was stratified by obesity status to preserve class proportions in both sets\n\nidx &lt;- createDataPartition(nhanes_svm$obese, p = 0.8, list = FALSE)\n\ntraining &lt;- nhanes_svm[idx, ]\ntesting  &lt;- nhanes_svm[-idx, ]\n\n# Ensure obese = positive class (otherwise can be non obese if R takes in alphabetical order...)\ntraining$obese &lt;- relevel(training$obese, ref = \"obese\")\ntesting$obese  &lt;- relevel(testing$obese, ref = \"obese\")",
    "crumbs": [
      "Home",
      "ML Portfolio",
      "NHANES - R Project",
      "Predicting Obesity using Support Vector Machines"
    ]
  },
  {
    "objectID": "ml-portfolio/02_nhanes_R/02_support_vector_machine.html#cross-validation-setup",
    "href": "ml-portfolio/02_nhanes_R/02_support_vector_machine.html#cross-validation-setup",
    "title": "Predicting Obesity using Support Vector Machines",
    "section": "3.4 Cross-validation setup",
    "text": "3.4 Cross-validation setup\nTo ensure reliable model evaluation, both SVM models were tuned using repeated 10-fold cross-validation.\n\ntrctrl &lt;- trainControl(method = \"repeatedcv\", number = 10, repeats = 3)",
    "crumbs": [
      "Home",
      "ML Portfolio",
      "NHANES - R Project",
      "Predicting Obesity using Support Vector Machines"
    ]
  },
  {
    "objectID": "ml-portfolio/02_nhanes_R/02_support_vector_machine.html#linear-svm",
    "href": "ml-portfolio/02_nhanes_R/02_support_vector_machine.html#linear-svm",
    "title": "Predicting Obesity using Support Vector Machines",
    "section": "3.5 Linear SVM",
    "text": "3.5 Linear SVM\n\nset.seed(123)\nsvm_linear &lt;- train(obese ~ ., data = training, method = \"svmLinear\", trControl = trctrl,\n                    preProcess = c(\"center\", \"scale\"), tuneLength = 10)\n\n\n\n\n\n\n\nNotesvm-linear summary\n\n\n\n\n\n\nsvm_linear\n\nSupport Vector Machines with Linear Kernel \n\n1649 samples\n  11 predictor\n   2 classes: 'obese', 'not_obese' \n\nPre-processing: centered (17), scaled (17) \nResampling: Cross-Validated (10 fold, repeated 3 times) \nSummary of sample sizes: 1484, 1484, 1485, 1484, 1484, 1484, ... \nResampling results:\n\n  Accuracy   Kappa       \n  0.6642449  -0.002979798\n\nTuning parameter 'C' was held constant at a value of 1\n\n\n\n\n\nLinear SVM performance\n\nset.seed(123)\ntest_pred_linear &lt;- predict(svm_linear, newdata = testing)\n\n\n\n\n\n\n\nNoteconfusion matrix result\n\n\n\n\n\n\nconfusionMatrix(test_pred_linear, testing$obese)\n\nConfusion Matrix and Statistics\n\n           Reference\nPrediction  obese not_obese\n  obese         0         0\n  not_obese   137       274\n                                          \n               Accuracy : 0.6667          \n                 95% CI : (0.6188, 0.7121)\n    No Information Rate : 0.6667          \n    P-Value [Acc &gt; NIR] : 0.5232          \n                                          \n                  Kappa : 0               \n                                          \n Mcnemar's Test P-Value : &lt;2e-16          \n                                          \n            Sensitivity : 0.0000          \n            Specificity : 1.0000          \n         Pos Pred Value :    NaN          \n         Neg Pred Value : 0.6667          \n             Prevalence : 0.3333          \n         Detection Rate : 0.0000          \n   Detection Prevalence : 0.0000          \n      Balanced Accuracy : 0.5000          \n                                          \n       'Positive' Class : obese           \n                                          \n\n\n\n\n\nResult:\nThe linear SVM performed poorly. It failed to identify any obese individuals (Sensitivity = 0), classifying all cases as not-obese. Although specificity was perfect (1.00), overall accuracy (66.7%) matched the no-information rate and Kappa was 0, indicating no predictive value beyond chance. These results show that obesity is not linearly separable using the available NHANES predictors; a single linear boundary cannot separate obese from non-obese individuals. This motivates the use of a non-linear model, such as the radial SVM, to capture more complex patterns.\n\n3.5.1 Radial SVM\n\nset.seed(46)\n\nsvm_radial &lt;- train(obese ~ ., data = training, method = \"svmRadial\", trControl = trctrl,\n                    preProcess = c(\"center\", \"scale\"), tuneLength = 10)\n\n\n\n\n\n\n\nNotesvm-radial summary\n\n\n\n\n\n\n\nShow code\nsvm_radial\n\n\nSupport Vector Machines with Radial Basis Function Kernel \n\n1649 samples\n  11 predictor\n   2 classes: 'obese', 'not_obese' \n\nPre-processing: centered (17), scaled (17) \nResampling: Cross-Validated (10 fold, repeated 3 times) \nSummary of sample sizes: 1484, 1484, 1485, 1484, 1484, 1484, ... \nResampling results across tuning parameters:\n\n  C       Accuracy   Kappa        \n    0.25  0.6668712  -0.0004016064\n    0.50  0.6757576   0.0496828773\n    1.00  0.6899015   0.1383094438\n    2.00  0.7042547   0.2205124782\n    4.00  0.7095073   0.2594899385\n    8.00  0.7238556   0.3223452098\n   16.00  0.7359941   0.3715718440\n   32.00  0.7400480   0.3943154247\n   64.00  0.7412614   0.4045355938\n  128.00  0.7440909   0.4181992286\n\nTuning parameter 'sigma' was held constant at a value of 0.04399537\nAccuracy was used to select the optimal model using the largest value.\nThe final values used for the model were sigma = 0.04399537 and C = 128.\n\n\n\n\n\nRadial SVM Performance\n\ntest_pred_radial &lt;- predict(svm_radial, newdata = testing)\n\n\n\n\n\n\n\nNoteconfusion matrix svm-radial\n\n\n\n\n\n\n\nShow code\nconfusionMatrix(test_pred_radial, testing$obese)\n\n\nConfusion Matrix and Statistics\n\n           Reference\nPrediction  obese not_obese\n  obese        78        49\n  not_obese    59       225\n                                          \n               Accuracy : 0.7372          \n                 95% CI : (0.6918, 0.7792)\n    No Information Rate : 0.6667          \n    P-Value [Acc &gt; NIR] : 0.0012          \n                                          \n                  Kappa : 0.3978          \n                                          \n Mcnemar's Test P-Value : 0.3865          \n                                          \n            Sensitivity : 0.5693          \n            Specificity : 0.8212          \n         Pos Pred Value : 0.6142          \n         Neg Pred Value : 0.7923          \n             Prevalence : 0.3333          \n         Detection Rate : 0.1898          \n   Detection Prevalence : 0.3090          \n      Balanced Accuracy : 0.6953          \n                                          \n       'Positive' Class : obese           \n                                          \n\n\n\n\n\nResults:\nThe radial SVM outperformed the linear model across all metrics. The best model (C = 128, sigma = 0.0428) achieved a cross‐validated accuracy of 74.1% and a test accuracy of 77.9%. Sensitivity improved substantially to 63.5%, correctly identifying nearly two thirds of obese individuals. Specificity remained strong at 85.0%, and Kappa increased to 0.49, indicating moderate predictive agreement. These results demonstrate that obesity classification requires a nonlinear decision boundary, and the radial kernel is better suited to capture these complex relationships in the NHANES data.",
    "crumbs": [
      "Home",
      "ML Portfolio",
      "NHANES - R Project",
      "Predicting Obesity using Support Vector Machines"
    ]
  },
  {
    "objectID": "ml-portfolio/02_nhanes_R/02_support_vector_machine.html#limitations",
    "href": "ml-portfolio/02_nhanes_R/02_support_vector_machine.html#limitations",
    "title": "Predicting Obesity using Support Vector Machines",
    "section": "3.6 Limitations",
    "text": "3.6 Limitations\nSeveral limitations should be considered:\n\nFeature limitations: Many potential predictors of obesity are absent from the selected NHANES subset, limiting the model’s ability to fully capture the underlying patterns.\nResidual imbalance: Although the dataset is not highly imbalanced, obesity accounted for approximately one-third of the sample, which may still influence sensitivity.\nModel interpretability: While the radial SVM provided better predictive performance, it is less interpretable than the linear model. Understanding which variables drive obesity risk becomes more difficult.\n\nOverall, the results demonstrate that SVM models can classify obesity with moderate accuracy using standard NHANES variables, but performance remains limited without richer predictors.",
    "crumbs": [
      "Home",
      "ML Portfolio",
      "NHANES - R Project",
      "Predicting Obesity using Support Vector Machines"
    ]
  },
  {
    "objectID": "ml-portfolio/02_nhanes_R/02_support_vector_machine.html#conclusion",
    "href": "ml-portfolio/02_nhanes_R/02_support_vector_machine.html#conclusion",
    "title": "Predicting Obesity using Support Vector Machines",
    "section": "3.7 Conclusion",
    "text": "3.7 Conclusion\nThis project compared linear and radial SVM models for predicting obesity from NHANES data. The linear SVM performed poorly, indicating that a simple linear decision boundary cannot separate obese and non-obese individuals based on the available predictors. In contrast, the radial SVM achieved substantially better accuracy and sensitivity, demonstrating that obesity requires a non-linear classification approach. Although performance improved, it remained moderate overall, reflecting the complexity of obesity and the limitations of the included variables. These findings highlight the value of non-linear methods in health classification tasks, while also underscoring the need for richer predictors to achieve stronger performance.",
    "crumbs": [
      "Home",
      "ML Portfolio",
      "NHANES - R Project",
      "Predicting Obesity using Support Vector Machines"
    ]
  },
  {
    "objectID": "ml-portfolio/03_diabetes_python/index.html",
    "href": "ml-portfolio/03_diabetes_python/index.html",
    "title": "Diabetes Readmission (Python)",
    "section": "",
    "text": "This section will contain the Python-based machine learning project analyzing hospital readmission patterns for diabetes patients.\nContent will be added soon.",
    "crumbs": [
      "Home",
      "ML Portfolio",
      "Diabetes Readmission - Python"
    ]
  },
  {
    "objectID": "standalone-projects/bitcoin_portfolio_R/index.html",
    "href": "standalone-projects/bitcoin_portfolio_R/index.html",
    "title": "Bitcoin & Portfolio Analysis – R",
    "section": "",
    "text": "This project examines Bitcoin returns, risk, correlations, and portfolio behavior using R.\nContent will be added soon.",
    "crumbs": [
      "Home",
      "Standalone Projects",
      "Bitcoin Portfolio (R)"
    ]
  },
  {
    "objectID": "standalone-projects/swiss_electricity_transition_R/index.html",
    "href": "standalone-projects/swiss_electricity_transition_R/index.html",
    "title": "Swiss Electricity Transition (R)",
    "section": "",
    "text": "This analysis joins Swiss energy-production data with solar radiation data from MeteoSwiss.\nContent will be added soon."
  }
]